from dataclasses import dataclass
import re
import subprocess
import concurrent.futures
import os
from pathlib import Path
import argparse

@dataclass
class URL:
    url: str
    entry_id: str
    domain: str


def download_single(url: URL, download_folder: Path):
    """Downloads the file from a single url."""
    output_path = os.path.join(download_folder, f'{url.entry_id}.mp4')
    if os.path.exists(output_path): # should not redownload downloaded videos
        print(f"{url.entry_id} already downloaded, continuing")
        return
    print(f"Downloading {url.entry_id}")
    command = [
        "yt-dlp",
        "--output", output_path, 
        url.url
    ]
    try:
        subprocess.run(command)
    except Exception as e:
        print(f"Error with video {url.entry_id}: {e}")


def download_all(urls: list[URL], download_folder: Path):
    """Downloads all files from a list of urls."""
    if not os.path.exists(download_folder):
        print("Download folder does not exist, exiting.")
        raise
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        future_downloads = [executor.submit(download_single, url, download_folder) for url in urls]
        for future in concurrent.futures.as_completed(future_downloads):
            print(future.result())


def parse_into_class(url_file: Path) -> list[URL]:
    """Takes the raw data generated by the browser extension and parses it."""
    urls = []
    domain_regex = re.compile(r"//(.*?).kaltura")
    entry_id_regex = re.compile(r"entryId/(.*?)/")
    # real file to work on, need to test stuff first
    with open(url_file, "r") as f:
        for line in f.readlines():
            url = line.split()[0]
            entry_id = entry_id_regex.search(url).group(1)
            domain = domain_regex.search(url).group(1)
            urls.append(URL(url, entry_id, domain))
    return urls


def trim_duplicates(urls: list[URL]) -> list[URL]:
    """Takes a list of urls and chooses one url for each entry_id."""
    final_urls = list(filter(lambda x: x.domain == "cdnapisec", urls))
    maybe_needed = list(filter(lambda x: x.domain != "cdnapisec", urls))

    for url in maybe_needed:
        if url.entry_id not in [x.entry_id for x in final_urls]:
            final_urls.append(url)
    return final_urls
    

def main():
    """Driver function."""
    # CLI Functionality
    parser = argparse.ArgumentParser(
        prog='BBVideoDownloader',
        description='Downloads the unique videos from a list of blackboard video '\
            'links generated by the BlackBoardLinkFinder extension.',
    )
    parser.add_argument('input_file')
    parser.add_argument('download_folder')
    args = parser.parse_args()
    urls = parse_into_class(Path(args.input_file))
    urls = trim_duplicates(urls)
    download_path = Path(args.download_folder)
    download_all(urls, download_path)


if __name__ == "__main__":
    main()
